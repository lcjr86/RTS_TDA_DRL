{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch DQN Trading - Improved Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# IMPORTANT: Use the IMPROVED environment\n",
    "from src.trading_env_improved import ImprovedTradingEnv\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = '1d'\n",
    "# timeframe = '1h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load scenario_config\n",
    "scenario_config = pd.read_csv(f'../config_files/scenarios_config_{timeframe}_baseline_v2.csv')\n",
    "\n",
    "# Format start_train_date, end_train_date, start_val_date, end_val_date\n",
    "scenario_config['start_train_date'] = pd.to_datetime(scenario_config['start_train_date'], format='%d/%m/%Y')\n",
    "scenario_config['end_train_date'] = pd.to_datetime(scenario_config['end_train_date'], format='%d/%m/%Y')\n",
    "scenario_config['start_val_date'] = pd.to_datetime(scenario_config['start_val_date'], format='%d/%m/%Y')\n",
    "scenario_config['end_val_date'] = pd.to_datetime(scenario_config['end_val_date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `feature_family.json` to get the feature family\n",
    "with open('../config_files/feature_family_v1.json') as f:\n",
    "    feature_family = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_members(family_name, data):\n",
    "    # Parse the JSON data if it's a string, otherwise use it as is\n",
    "    if isinstance(data, str):\n",
    "        data = json.loads(data)\n",
    "    \n",
    "    # Find the family with the given name\n",
    "    for family in data['Families']:\n",
    "        if family['Name'] == family_name:\n",
    "            # Return a list of member names\n",
    "            return [member['Name'] for member in family['Members']]\n",
    "    \n",
    "    # If family not found, return None or an empty list\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given scenario from scenario_config, get each column into a new variable\n",
    "\n",
    "def get_scenario_data(scenario_name, scenario_config):\n",
    "    # Get the scenario row\n",
    "    scenario = scenario_config[scenario_config['scenario'] == scenario_name].iloc[0]\n",
    "    \n",
    "    # Get the data for the scenario\n",
    "    scenario_data = {\n",
    "        'asset': scenario['asset'],\n",
    "        'feature_family': scenario['feature_family'],\n",
    "        'start_train_date': scenario['start_train_date'],\n",
    "        'end_train_date': scenario['end_train_date'],\n",
    "        'start_val_date': scenario['start_val_date'],\n",
    "        'end_val_date': scenario['end_val_date'],\n",
    "        'feature_path': scenario['feature_path'],\n",
    "        'feature_file': scenario['feature_file'],\n",
    "        'raw_path': scenario['raw_path'],\n",
    "        'raw_file': scenario['raw_file'],\n",
    "    }\n",
    "    \n",
    "    return scenario_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Transaction Costs\n",
    "\n",
    "Set realistic transaction costs based on asset type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC/USDT transaction cost: 0.020%\n",
      "SPY transaction cost: 0.010%\n"
     ]
    }
   ],
   "source": [
    "def get_transaction_cost(asset_name):\n",
    "    \"\"\"\n",
    "    Determine transaction cost based on asset type\n",
    "    \n",
    "    Crypto (USDT pairs): 0.02% (0.0002) - Binance maker fee\n",
    "    Traditional assets: 0.01% (0.0001)\n",
    "    \"\"\"\n",
    "    if 'USDT' in asset_name:\n",
    "        return 0.0002  # 0.02% for crypto\n",
    "    else:\n",
    "        return 0.0001  # 0.01% for traditional assets\n",
    "\n",
    "# Test\n",
    "print(f\"BTC/USDT transaction cost: {get_transaction_cost('BTCUSDT')*100:.3f}%\")\n",
    "print(f\"SPY transaction cost: {get_transaction_cost('SPY')*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import warnings\n",
    "\n",
    "\n",
    "def calculate_feature_variability(series: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate multiple variability metrics for a single feature.\n",
    "    \n",
    "    Returns dict with:\n",
    "    - std: Standard deviation\n",
    "    - cv: Coefficient of variation (std/mean) - scale-independent\n",
    "    - iqr: Interquartile range\n",
    "    - range_ratio: (max-min)/mean - relative range\n",
    "    - unique_ratio: Number of unique values / total values\n",
    "    - mad: Mean absolute deviation\n",
    "    - entropy: Shannon entropy of binned values\n",
    "    \"\"\"\n",
    "    # Handle NaN/inf\n",
    "    clean_series = series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    if len(clean_series) < 10:\n",
    "        return {\n",
    "            'std': 0, 'cv': 0, 'iqr': 0, 'range_ratio': 0,\n",
    "            'unique_ratio': 0, 'mad': 0, 'entropy': 0\n",
    "        }\n",
    "    \n",
    "    mean_val = clean_series.mean()\n",
    "    std_val = clean_series.std()\n",
    "    \n",
    "    # Coefficient of Variation (handle zero mean)\n",
    "    cv = std_val / abs(mean_val) if abs(mean_val) > 1e-10 else 0\n",
    "    \n",
    "    # Interquartile Range\n",
    "    q75, q25 = np.percentile(clean_series, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # Range ratio\n",
    "    range_val = clean_series.max() - clean_series.min()\n",
    "    range_ratio = range_val / abs(mean_val) if abs(mean_val) > 1e-10 else range_val\n",
    "    \n",
    "    # Unique ratio\n",
    "    unique_ratio = clean_series.nunique() / len(clean_series)\n",
    "    \n",
    "    # Mean Absolute Deviation\n",
    "    mad = (clean_series - mean_val).abs().mean()\n",
    "    \n",
    "    # Entropy (binned)\n",
    "    try:\n",
    "        hist, _ = np.histogram(clean_series, bins=20)\n",
    "        hist = hist / hist.sum()\n",
    "        hist = hist[hist > 0]  # Remove zeros for log\n",
    "        entropy = -np.sum(hist * np.log2(hist))\n",
    "    except:\n",
    "        entropy = 0\n",
    "    \n",
    "    return {\n",
    "        'std': std_val,\n",
    "        'cv': cv,\n",
    "        'iqr': iqr,\n",
    "        'range_ratio': range_ratio,\n",
    "        'unique_ratio': unique_ratio,\n",
    "        'mad': mad,\n",
    "        'entropy': entropy\n",
    "    }\n",
    "\n",
    "\n",
    "def is_feature_flat(\n",
    "    series: pd.Series,\n",
    "    cv_threshold: float = 0.01,\n",
    "    unique_threshold: float = 0.01,\n",
    "    entropy_threshold: float = 1.0,\n",
    "    method: str = 'combined'\n",
    ") -> Tuple[bool, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Determine if a feature is flat/near-flat.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        The feature values\n",
    "    cv_threshold : float\n",
    "        Coefficient of variation threshold. Below this = flat.\n",
    "        Default 0.01 means std < 1% of mean\n",
    "    unique_threshold : float\n",
    "        Unique ratio threshold. Below this = flat.\n",
    "        Default 0.01 means <1% unique values\n",
    "    entropy_threshold : float\n",
    "        Entropy threshold. Below this = flat.\n",
    "        Default 1.0 (max entropy for 20 bins is ~4.3)\n",
    "    method : str\n",
    "        How to combine criteria:\n",
    "        - 'any': Flat if ANY criterion says flat\n",
    "        - 'all': Flat only if ALL criteria say flat\n",
    "        - 'combined': Use weighted combination (recommended)\n",
    "        - 'cv': Use only coefficient of variation\n",
    "        - 'entropy': Use only entropy\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    is_flat : bool\n",
    "        True if feature is considered flat\n",
    "    metrics : dict\n",
    "        All calculated variability metrics\n",
    "    \"\"\"\n",
    "    metrics = calculate_feature_variability(series)\n",
    "    \n",
    "    # Individual flat checks\n",
    "    cv_flat = metrics['cv'] < cv_threshold\n",
    "    unique_flat = metrics['unique_ratio'] < unique_threshold\n",
    "    entropy_flat = metrics['entropy'] < entropy_threshold\n",
    "    \n",
    "    if method == 'cv':\n",
    "        is_flat = cv_flat\n",
    "    elif method == 'entropy':\n",
    "        is_flat = entropy_flat\n",
    "    elif method == 'any':\n",
    "        is_flat = cv_flat or unique_flat or entropy_flat\n",
    "    elif method == 'all':\n",
    "        is_flat = cv_flat and unique_flat and entropy_flat\n",
    "    elif method == 'combined':\n",
    "        # Weighted score: higher = more varied\n",
    "        # Normalize each metric to 0-1 range approximately\n",
    "        cv_score = min(metrics['cv'] / 0.5, 1.0)  # 0.5 CV = max score\n",
    "        entropy_score = min(metrics['entropy'] / 4.0, 1.0)  # 4.0 entropy = max score\n",
    "        unique_score = min(metrics['unique_ratio'] / 0.5, 1.0)  # 50% unique = max score\n",
    "        \n",
    "        combined_score = 0.4 * cv_score + 0.4 * entropy_score + 0.2 * unique_score\n",
    "        is_flat = combined_score < 0.1  # Threshold for combined score\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return is_flat, metrics\n",
    "\n",
    "\n",
    "def filter_flat_features(\n",
    "    df: pd.DataFrame,\n",
    "    feature_columns: Optional[List[str]] = None,\n",
    "    cv_threshold: float = 0.01,\n",
    "    unique_threshold: float = 0.01,\n",
    "    entropy_threshold: float = 1.0,\n",
    "    method: str = 'combined',\n",
    "    verbose: bool = True\n",
    ") -> Tuple[List[str], List[str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Filter out flat/near-flat features from a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing features\n",
    "    feature_columns : List[str], optional\n",
    "        List of feature column names to check.\n",
    "        If None, uses all numeric columns except 'close', 'date', etc.\n",
    "    cv_threshold : float\n",
    "        Coefficient of variation threshold\n",
    "    unique_threshold : float\n",
    "        Unique ratio threshold\n",
    "    entropy_threshold : float\n",
    "        Entropy threshold\n",
    "    method : str\n",
    "        Method to determine flatness\n",
    "    verbose : bool\n",
    "        Print details about filtered features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    selected_features : List[str]\n",
    "        Features that passed the filter (not flat)\n",
    "    removed_features : List[str]\n",
    "        Features that were removed (flat)\n",
    "    metrics_df : pd.DataFrame\n",
    "        Variability metrics for all features\n",
    "    \"\"\"\n",
    "    # Determine feature columns\n",
    "    if feature_columns is None:\n",
    "        exclude_cols = ['close', 'open', 'high', 'low', 'volume', 'date', \n",
    "                       'end_date', 'start_date', 'timestamp']\n",
    "        feature_columns = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                          if col.lower() not in exclude_cols]\n",
    "    \n",
    "    selected_features = []\n",
    "    removed_features = []\n",
    "    all_metrics = []\n",
    "    \n",
    "    for col in feature_columns:\n",
    "        is_flat, metrics = is_feature_flat(\n",
    "            df[col],\n",
    "            cv_threshold=cv_threshold,\n",
    "            unique_threshold=unique_threshold,\n",
    "            entropy_threshold=entropy_threshold,\n",
    "            method=method\n",
    "        )\n",
    "        \n",
    "        metrics['feature'] = col\n",
    "        metrics['is_flat'] = is_flat\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        if is_flat:\n",
    "            removed_features.append(col)\n",
    "        else:\n",
    "            selected_features.append(col)\n",
    "    \n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    metrics_df = metrics_df[['feature', 'is_flat', 'cv', 'entropy', 'std', \n",
    "                             'iqr', 'range_ratio', 'unique_ratio', 'mad']]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(\"FEATURE VARIABILITY ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nTotal features analyzed: {len(feature_columns)}\")\n",
    "        print(f\"Features KEPT (varied): {len(selected_features)}\")\n",
    "        print(f\"Features REMOVED (flat): {len(removed_features)}\")\n",
    "        \n",
    "        if removed_features:\n",
    "            print(f\"\\n⚠️  Removed flat features:\")\n",
    "            for feat in removed_features:\n",
    "                m = metrics_df[metrics_df['feature'] == feat].iloc[0]\n",
    "                print(f\"   - {feat}: CV={m['cv']:.4f}, Entropy={m['entropy']:.2f}\")\n",
    "        \n",
    "        if selected_features:\n",
    "            print(f\"\\n✓ Selected features with variation:\")\n",
    "            for feat in selected_features:\n",
    "                m = metrics_df[metrics_df['feature'] == feat].iloc[0]\n",
    "                print(f\"   - {feat}: CV={m['cv']:.4f}, Entropy={m['entropy']:.2f}\")\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    return selected_features, removed_features, metrics_df\n",
    "\n",
    "\n",
    "def select_varied_features(\n",
    "    df: pd.DataFrame,\n",
    "    feature_columns: List[str],\n",
    "    min_cv: float = 0.01,\n",
    "    min_entropy: float = 1.0,\n",
    "    top_n: Optional[int] = None,\n",
    "    verbose: bool = True\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Simple function to select features with sufficient variation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe with features\n",
    "    feature_columns : List[str]\n",
    "        Feature column names to evaluate\n",
    "    min_cv : float\n",
    "        Minimum coefficient of variation required\n",
    "    min_entropy : float\n",
    "        Minimum entropy required\n",
    "    top_n : int, optional\n",
    "        If provided, return only top N features by variability\n",
    "    verbose : bool\n",
    "        Print summary\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List[str] : Selected feature names\n",
    "    \"\"\"\n",
    "    selected, removed, metrics = filter_flat_features(\n",
    "        df, \n",
    "        feature_columns=feature_columns,\n",
    "        cv_threshold=min_cv,\n",
    "        entropy_threshold=min_entropy,\n",
    "        method='combined',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if top_n is not None and len(selected) > top_n:\n",
    "        # Rank by combined variability and take top N\n",
    "        varied_metrics = metrics[~metrics['is_flat']].copy()\n",
    "        varied_metrics['variability_score'] = (\n",
    "            varied_metrics['cv'].rank(pct=True) * 0.4 +\n",
    "            varied_metrics['entropy'].rank(pct=True) * 0.4 +\n",
    "            varied_metrics['unique_ratio'].rank(pct=True) * 0.2\n",
    "        )\n",
    "        varied_metrics = varied_metrics.sort_values('variability_score', ascending=False)\n",
    "        selected = varied_metrics.head(top_n)['feature'].tolist()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Selected {len(selected)}/{len(feature_columns)} features with sufficient variation\")\n",
    "        if removed:\n",
    "            print(f\"Removed {len(removed)} flat features: {removed}\")\n",
    "    \n",
    "    return selected\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONVENIENCE FUNCTION FOR YOUR WORKFLOW\n",
    "# =============================================================================\n",
    "\n",
    "def filter_tda_features(\n",
    "    df_features: pd.DataFrame,\n",
    "    list_features: List[str],\n",
    "    cv_threshold: float = 0.05,\n",
    "    entropy_threshold: float = 2.0,\n",
    "    verbose: bool = True\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Filter TDA features to remove flat/constant ones.\n",
    "    \n",
    "    This is the main function to use in your preprocessing pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_features : pd.DataFrame\n",
    "        Feature dataframe (with date as index)\n",
    "    list_features : List[str]\n",
    "        List of feature column names\n",
    "    cv_threshold : float\n",
    "        Minimum coefficient of variation (default 0.05 = 5%)\n",
    "        Higher value = stricter filtering\n",
    "    entropy_threshold : float\n",
    "        Minimum entropy (default 2.0)\n",
    "        Higher value = stricter filtering\n",
    "    verbose : bool\n",
    "        Print analysis details\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    List[str] : Filtered feature names (only varied features)\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> # Before training\n",
    "    >>> list_features = get_family_members('TDA_TD_168_SS_720', feature_family)\n",
    "    >>> list_features = filter_tda_features(df_features, list_features)\n",
    "    >>> df_features = df_features[list_features]\n",
    "    \"\"\"\n",
    "    selected, removed, metrics = filter_flat_features(\n",
    "        df_features,\n",
    "        feature_columns=list_features,\n",
    "        cv_threshold=cv_threshold,\n",
    "        entropy_threshold=entropy_threshold,\n",
    "        method='combined',\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    if len(selected) == 0:\n",
    "        warnings.warn(\"All features were filtered out! Using original features.\")\n",
    "        return list_features\n",
    "    \n",
    "    return selected\n",
    "\n",
    "\n",
    "def filter_tda_features_strict(\n",
    "    df_features: pd.DataFrame,\n",
    "    list_features: List[str],\n",
    "    min_cv: float = 0.1,\n",
    "    min_range_pct: float = 0.2,\n",
    "    verbose: bool = True\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Stricter filtering using coefficient of variation and range.\n",
    "    \n",
    "    A feature is kept only if:\n",
    "    - CV (std/mean) > min_cv  (default 10%)\n",
    "    - Range (max-min)/mean > min_range_pct (default 20%)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_features : pd.DataFrame\n",
    "        Feature dataframe\n",
    "    list_features : List[str]\n",
    "        Feature column names\n",
    "    min_cv : float\n",
    "        Minimum coefficient of variation (0.1 = 10%)\n",
    "    min_range_pct : float\n",
    "        Minimum range as % of mean (0.2 = 20%)\n",
    "    verbose : bool\n",
    "        Print details\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List[str] : Selected feature names\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    removed = []\n",
    "    \n",
    "    for col in list_features:\n",
    "        series = df_features[col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        \n",
    "        if len(series) < 10:\n",
    "            removed.append((col, 'insufficient data'))\n",
    "            continue\n",
    "            \n",
    "        mean_val = abs(series.mean())\n",
    "        std_val = series.std()\n",
    "        range_val = series.max() - series.min()\n",
    "        \n",
    "        cv = std_val / mean_val if mean_val > 1e-10 else 0\n",
    "        range_pct = range_val / mean_val if mean_val > 1e-10 else 0\n",
    "        \n",
    "        if cv >= min_cv and range_pct >= min_range_pct:\n",
    "            selected.append(col)\n",
    "            if verbose:\n",
    "                print(f\"✓ {col}: CV={cv:.3f}, Range%={range_pct:.3f}\")\n",
    "        else:\n",
    "            removed.append((col, f'CV={cv:.3f}, Range%={range_pct:.3f}'))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Selected: {len(selected)}/{len(list_features)} features\")\n",
    "        if removed:\n",
    "            print(f\"\\nRemoved {len(removed)} flat features:\")\n",
    "            for feat, reason in removed:\n",
    "                print(f\"  ❌ {feat}: {reason}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(selected) == 0:\n",
    "        warnings.warn(\"All features filtered! Returning original list.\")\n",
    "        return list_features\n",
    "        \n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Scenarios to Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 23 scenarios\n"
     ]
    }
   ],
   "source": [
    "# Create a list_scenario_id that are integers from 1 to 23\n",
    "list_scenario_id = list(range(1, 24))\n",
    "\n",
    "# list_scenario_id = [21]  # For testing\n",
    "\n",
    "print(f\"Processing {len(list_scenario_id)} scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Loop\n",
    "\n",
    "Process each scenario with improved environment and proper cost tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results directories created\n"
     ]
    }
   ],
   "source": [
    "# Create results directories\n",
    "os.makedirs('../RL_outputs/results/df', exist_ok=True)\n",
    "os.makedirs('../RL_outputs/results/json', exist_ok=True)\n",
    "os.makedirs('../RL_outputs/results/plot', exist_ok=True)\n",
    "os.makedirs('../RL_outputs/tensorboard', exist_ok=True)\n",
    "os.makedirs('../RL_outputs/models', exist_ok=True)\n",
    "os.makedirs('../RL_outputs/logs', exist_ok=True)\n",
    "os.makedirs('../RL_outputs/checkpoints', exist_ok=True)\n",
    "\n",
    "print(\"Results directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing Scenario 1 (1/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: SMA\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 3 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)  - Transaction cost: 0.0200% per trade\n",
      "\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG  - Transaction cost: 0.0200% per trade\n",
      "\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=1.13 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=1.72 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):      0.26%\n",
      "Total Return (before costs):     1.64%\n",
      "Sharpe Ratio (after costs):     0.683\n",
      "Sharpe Ratio (before costs):    0.693\n",
      "Win Rate:                       52.94%\n",
      "Total Trades:                      34\n",
      "Total Transaction Costs:     $   16.67\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 1 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 2 (2/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: EMA\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 3 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Cost per position flip: 0.0400% (2 trades)  - Initial position: LONG\n",
      "\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.14 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=1.47 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=0.93 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=1.66 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=68240, episode_reward=1.78 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=0.19 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=0.83 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):     97.08%\n",
      "Total Return (before costs):   100.90%\n",
      "Sharpe Ratio (after costs):     0.903\n",
      "Sharpe Ratio (before costs):    0.916\n",
      "Win Rate:                       51.34%\n",
      "Total Trades:                      48\n",
      "Total Transaction Costs:     $   40.68\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 2 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 3 (3/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: RSI\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 3 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:Improved Environment initialized:\n",
      "\n",
      "  - Features in df: 4\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Expected observation size: 90  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)  - Cost per position flip: 0.0400% (2 trades)\n",
      "\n",
      "  - Initial position: LONG\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-0.77 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-0.35 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=-0.17 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=-0.10 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=68240, episode_reward=0.19 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=1.10 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=1.18 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):     -7.03%\n",
      "Total Return (before costs):    -2.50%\n",
      "Sharpe Ratio (after costs):     0.384\n",
      "Sharpe Ratio (before costs):    0.417\n",
      "Win Rate:                       54.01%\n",
      "Total Trades:                     119\n",
      "Total Transaction Costs:     $   72.99\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 3 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 4 (4/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: MACD\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 3 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "Improved Environment initialized:\n",
      "  - Transaction cost: 0.0200% per trade  - Features in df: 4\n",
      "\n",
      "  - Cost per position flip: 0.0400% (2 trades)  - Lookback window: 20\n",
      "\n",
      "  - Initial position: LONG  - Expected observation size: 90\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "Improved Environment initialized:\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=1.48 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=0.16 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=1.93 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=68240, episode_reward=2.04 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=2.79 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=0.84 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -62.86%\n",
      "Total Return (before costs):   -62.36%\n",
      "Sharpe Ratio (after costs):     0.001\n",
      "Sharpe Ratio (before costs):    0.010\n",
      "Win Rate:                       52.41%\n",
      "Total Trades:                      33\n",
      "Total Transaction Costs:     $    9.27\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 4 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 5 (5/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: BB\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 9 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 10\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 216\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 10\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 216\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 10\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 216\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 10\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 216\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 10\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 216\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-0.16 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.75 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=0.86 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=0.85 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=0.49 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -58.90%\n",
      "Total Return (before costs):   -57.64%\n",
      "Sharpe Ratio (after costs):    -0.188\n",
      "Sharpe Ratio (before costs):   -0.167\n",
      "Win Rate:                       49.73%\n",
      "Total Trades:                      75\n",
      "Total Transaction Costs:     $   19.65\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 5 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 6 (6/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: SO\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 6 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-1.15 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-1.73 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=-1.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=-1.10 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=68240, episode_reward=0.41 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=-0.72 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-0.45 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -59.11%\n",
      "Total Return (before costs):   -56.64%\n",
      "Sharpe Ratio (after costs):     0.066\n",
      "Sharpe Ratio (before costs):    0.106\n",
      "Win Rate:                       52.14%\n",
      "Total Trades:                     147\n",
      "Total Transaction Costs:     $   48.80\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 6 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 7 (7/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: ATR\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 3 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:  - Lookback window: 20\n",
      "\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90  - Expected observation size: 90\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Transaction cost: 0.0200% per trade  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "\n",
      "  - Initial position: LONG\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-0.53 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.89 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=1.02 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=0.99 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=1.04 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=1.36 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=0.54 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -54.53%\n",
      "Total Return (before costs):   -54.07%\n",
      "Sharpe Ratio (after costs):     0.132\n",
      "Sharpe Ratio (before costs):    0.139\n",
      "Win Rate:                       50.00%\n",
      "Total Trades:                      25\n",
      "Total Transaction Costs:     $    9.49\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 7 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 8 (8/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: lagged\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 6 features\n",
      "Train: 192 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:Improved Environment initialized:\n",
      "\n",
      "  - Features in df: 7  - Features in df: 7\n",
      "\n",
      "  - Lookback window: 20  - Lookback window: 20\n",
      "\n",
      "  - Expected observation size: 153  - Expected observation size: 153\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "Improved Environment initialized:  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "\n",
      "  - Initial position: LONG\n",
      "  - Transaction cost: 0.0200% per trade  - Features in df: 7\n",
      "\n",
      "  - Lookback window: 20  - Cost per position flip: 0.0400% (2 trades)\n",
      "\n",
      "  - Initial position: LONG  - Expected observation size: 153\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=3072, episode_reward=-0.14 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6144, episode_reward=-1.42 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=9216, episode_reward=-1.97 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=12288, episode_reward=-2.48 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=15360, episode_reward=-2.55 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=18432, episode_reward=-2.11 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=21504, episode_reward=-2.63 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=24576, episode_reward=-1.83 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=27648, episode_reward=-1.29 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=30720, episode_reward=-1.46 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=33792, episode_reward=-0.51 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=36864, episode_reward=-1.18 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=39936, episode_reward=-0.70 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=43008, episode_reward=-0.50 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=46080, episode_reward=-0.87 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=49152, episode_reward=-1.11 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=52224, episode_reward=-1.47 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=55296, episode_reward=-0.35 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=58368, episode_reward=-1.31 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=61440, episode_reward=-1.82 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=64512, episode_reward=-0.79 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=67584, episode_reward=-0.86 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=70656, episode_reward=-0.89 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=73728, episode_reward=-0.34 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=76800, episode_reward=-0.71 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=79872, episode_reward=0.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=82944, episode_reward=0.40 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=86016, episode_reward=0.28 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=89088, episode_reward=0.14 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=92160, episode_reward=0.42 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95232, episode_reward=1.82 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=98304, episode_reward=1.98 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    199.78%\n",
      "Total Return (before costs):   227.23%\n",
      "Sharpe Ratio (after costs):     1.194\n",
      "Sharpe Ratio (before costs):    1.255\n",
      "Win Rate:                       50.27%\n",
      "Total Trades:                     219\n",
      "Total Transaction Costs:     $  192.38\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 8 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 9 (9/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: datetime\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 7 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "Improved Environment initialized:Improved Environment initialized:\n",
      "  - Features in df: 8\n",
      "Improved Environment initialized:  - Lookback window: 20\n",
      "\n",
      "  - Expected observation size: 174\n",
      "  - Features in df: 8  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 174\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)  - Transaction cost: 0.0200% per trade\n",
      "\n",
      "  - Initial position: LONG\n",
      "  - Cost per position flip: 0.0400% (2 trades)  - Features in df: 8\n",
      "  - Initial position: LONG\n",
      "\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 174\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "\n",
      "  - Features in df: 8\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 174\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 8\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 174\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-0.36 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-1.44 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=0.28 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=-0.10 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-0.52 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=0.78 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=-0.06 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -84.23%\n",
      "Total Return (before costs):   -83.60%\n",
      "Sharpe Ratio (after costs):    -0.843\n",
      "Sharpe Ratio (before costs):   -0.816\n",
      "Win Rate:                       47.59%\n",
      "Total Trades:                      98\n",
      "Total Transaction Costs:     $   12.56\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 9 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 10 (10/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: difference_and_change\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 12 features\n",
      "Train: 192 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "Improved Environment initialized:  - Features in df: 13\n",
      "\n",
      "  - Lookback window: 20\n",
      "  - Features in df: 13  - Expected observation size: 279\n",
      "\n",
      "  - Lookback window: 20  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Expected observation size: 279\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "Improved Environment initialized:  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Transaction cost: 0.0200% per tradeImproved Environment initialized:\n",
      "\n",
      "  - Initial position: LONG\n",
      "\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Features in df: 13  - Initial position: LONG\n",
      "\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 279\n",
      "  - Features in df: 13  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 279\n",
      "  - Transaction cost: 0.0200% per trade  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 13\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 279\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=3072, episode_reward=-0.47 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6144, episode_reward=-0.43 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=9216, episode_reward=-0.37 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12288, episode_reward=-0.79 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=15360, episode_reward=-0.86 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=18432, episode_reward=-0.58 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=21504, episode_reward=-1.12 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=24576, episode_reward=-0.41 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=27648, episode_reward=-1.05 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=30720, episode_reward=-1.30 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=33792, episode_reward=-0.48 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=36864, episode_reward=0.42 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=39936, episode_reward=-0.84 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=43008, episode_reward=0.16 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=46080, episode_reward=-0.09 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=49152, episode_reward=-0.26 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=52224, episode_reward=-0.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=55296, episode_reward=-0.52 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=58368, episode_reward=-1.11 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=61440, episode_reward=-0.17 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=64512, episode_reward=-0.74 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=67584, episode_reward=-0.56 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=70656, episode_reward=-0.60 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=73728, episode_reward=-0.72 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=76800, episode_reward=-0.17 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=79872, episode_reward=-0.05 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=82944, episode_reward=-1.34 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=86016, episode_reward=-0.37 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=89088, episode_reward=-1.93 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=92160, episode_reward=-1.28 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95232, episode_reward=-0.76 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=98304, episode_reward=-1.22 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -68.78%\n",
      "Total Return (before costs):   -66.25%\n",
      "Sharpe Ratio (after costs):    -0.128\n",
      "Sharpe Ratio (before costs):   -0.074\n",
      "Win Rate:                       52.41%\n",
      "Total Trades:                     195\n",
      "Total Transaction Costs:     $   65.50\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 10 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 11 (11/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: temporal_decomposition\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 3 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 4\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 90\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-0.15 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-0.35 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=0.38 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=-0.77 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-0.72 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=-1.47 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-4.13 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -98.43%\n",
      "Total Return (before costs):   -98.29%\n",
      "Sharpe Ratio (after costs):    -2.206\n",
      "Sharpe Ratio (before costs):   -2.149\n",
      "Win Rate:                       46.52%\n",
      "Total Trades:                     202\n",
      "Total Transaction Costs:     $   35.46\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 11 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 12 (12/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: time_delay_embedding\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "❌ ERROR in scenario 12: \"['time_delay_21_in_days_dimension_3_dimension_embedding_pca_1', 'time_delay_30_in_days_dimension_3_dimension_embedding_pca_1'] not in index\"\n",
      "Continuing to next scenario...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 13 (13/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_72_SS_336\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=1.300, Range%=5.754\n",
      "✓ connected_components_amplitude: CV=0.422, Range%=3.029\n",
      "✓ loops_amplitude: CV=0.495, Range%=3.161\n",
      "✓ voids_amplitude: CV=2.987, Range%=30.886\n",
      "✓ voids_number_of_points: CV=1.351, Range%=7.331\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.013, Range%=0.085\n",
      "  ❌ loops_entropy: CV=0.028, Range%=0.168\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.086, Range%=0.520\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=2.18 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=1.93 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=1.68 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=1.34 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=1.69 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=1.54 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=1.54 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):     88.64%\n",
      "Total Return (before costs):   101.35%\n",
      "Sharpe Ratio (after costs):     0.874\n",
      "Sharpe Ratio (before costs):    0.919\n",
      "Win Rate:                       52.67%\n",
      "Total Trades:                     163\n",
      "Total Transaction Costs:     $  120.69\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 13 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 14 (14/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_72_SS_504\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=5.620, Range%=23.029\n",
      "✓ connected_components_amplitude: CV=0.403, Range%=2.911\n",
      "✓ loops_amplitude: CV=0.423, Range%=3.716\n",
      "✓ voids_amplitude: CV=2.378, Range%=21.879\n",
      "✓ voids_number_of_points: CV=1.011, Range%=6.898\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.012, Range%=0.073\n",
      "  ❌ loops_entropy: CV=0.020, Range%=0.154\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.067, Range%=0.443\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20Improved Environment initialized:\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Features in df: 6  - Transaction cost: 0.0200% per trade\n",
      "\n",
      "  - Lookback window: 20  - Cost per position flip: 0.0400% (2 trades)\n",
      "\n",
      "  - Expected observation size: 132  - Initial position: LONG\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.35 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-0.78 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=-0.81 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=-1.62 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-1.43 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=-0.86 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=0.19 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -60.38%\n",
      "Total Return (before costs):   -58.53%\n",
      "Sharpe Ratio (after costs):    -0.211\n",
      "Sharpe Ratio (before costs):   -0.180\n",
      "Win Rate:                       50.00%\n",
      "Total Trades:                     114\n",
      "Total Transaction Costs:     $   24.11\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 14 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 15 (15/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_72_SS_720\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=3.120, Range%=12.714\n",
      "✓ connected_components_amplitude: CV=0.371, Range%=1.969\n",
      "✓ loops_amplitude: CV=0.359, Range%=1.886\n",
      "✓ voids_amplitude: CV=2.036, Range%=22.153\n",
      "✓ voids_number_of_points: CV=0.777, Range%=3.779\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.011, Range%=0.065\n",
      "  ❌ loops_entropy: CV=0.016, Range%=0.114\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.053, Range%=0.377\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-1.05 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-0.17 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=0.52 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=-0.06 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-0.56 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=0.33 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-0.13 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -75.75%\n",
      "Total Return (before costs):   -74.85%\n",
      "Sharpe Ratio (after costs):    -0.296\n",
      "Sharpe Ratio (before costs):   -0.271\n",
      "Win Rate:                       52.94%\n",
      "Total Trades:                      91\n",
      "Total Transaction Costs:     $   31.72\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 15 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 16 (16/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_72_SS_1080\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=1.042, Range%=4.708\n",
      "✓ connected_components_amplitude: CV=0.348, Range%=1.984\n",
      "✓ loops_amplitude: CV=0.361, Range%=3.035\n",
      "✓ voids_amplitude: CV=1.659, Range%=16.260\n",
      "✓ voids_number_of_points: CV=0.604, Range%=3.268\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.010, Range%=0.056\n",
      "  ❌ loops_entropy: CV=0.011, Range%=0.072\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.038, Range%=0.239\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.90 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=0.07 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=1.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=68240, episode_reward=2.48 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=2.37 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=2.43 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):     -3.09%\n",
      "Total Return (before costs):     0.02%\n",
      "Sharpe Ratio (after costs):     0.664\n",
      "Sharpe Ratio (before costs):    0.686\n",
      "Win Rate:                       52.14%\n",
      "Total Trades:                      79\n",
      "Total Transaction Costs:     $   25.61\n",
      "\n",
      "⚠️  Profitable before costs, loses after - overtrading\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 16 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 17 (17/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_168_SS_336\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=0.758, Range%=3.739\n",
      "✓ connected_components_amplitude: CV=0.443, Range%=2.996\n",
      "✓ loops_amplitude: CV=0.501, Range%=3.130\n",
      "✓ voids_amplitude: CV=3.184, Range%=35.776\n",
      "✓ loops_number_of_points: CV=0.110, Range%=0.783\n",
      "✓ voids_number_of_points: CV=1.690, Range%=9.265\n",
      "\n",
      "============================================================\n",
      "Selected: 6/9 features\n",
      "\n",
      "Removed 3 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.016, Range%=0.104\n",
      "  ❌ loops_entropy: CV=0.042, Range%=0.281\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'loops_number_of_points', 'voids_number_of_points']\n",
      "Using 6 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 7\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 153\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=1.06 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-0.38 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=1.34 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=0.30 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-0.91 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=-1.39 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-2.06 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -95.63%\n",
      "Total Return (before costs):   -95.40%\n",
      "Sharpe Ratio (after costs):    -1.491\n",
      "Sharpe Ratio (before costs):   -1.455\n",
      "Win Rate:                       45.99%\n",
      "Total Trades:                     128\n",
      "Total Transaction Costs:     $   23.35\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 17 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 18 (18/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_168_SS_504\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=1.877, Range%=8.621\n",
      "✓ connected_components_amplitude: CV=0.429, Range%=2.315\n",
      "✓ loops_amplitude: CV=0.451, Range%=3.074\n",
      "✓ voids_amplitude: CV=2.767, Range%=31.684\n",
      "✓ voids_number_of_points: CV=1.151, Range%=8.580\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.014, Range%=0.094\n",
      "  ❌ loops_entropy: CV=0.022, Range%=0.139\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.069, Range%=0.470\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.87 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=2.00 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=1.02 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=0.19 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-0.87 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=0.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=0.42 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):     26.94%\n",
      "Total Return (before costs):    32.65%\n",
      "Sharpe Ratio (after costs):     0.592\n",
      "Sharpe Ratio (before costs):    0.623\n",
      "Win Rate:                       50.53%\n",
      "Total Trades:                     110\n",
      "Total Transaction Costs:     $   86.73\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 18 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 19 (19/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_168_SS_720\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=8.146, Range%=33.898\n",
      "✓ connected_components_amplitude: CV=0.422, Range%=2.270\n",
      "✓ loops_amplitude: CV=0.407, Range%=2.470\n",
      "✓ voids_amplitude: CV=2.100, Range%=28.016\n",
      "✓ voids_number_of_points: CV=0.859, Range%=5.370\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.013, Range%=0.085\n",
      "  ❌ loops_entropy: CV=0.015, Range%=0.084\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.051, Range%=0.325\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.20 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.88 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=0.99 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=-0.52 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-1.72 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=-1.11 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-0.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -92.29%\n",
      "Total Return (before costs):   -91.98%\n",
      "Sharpe Ratio (after costs):    -1.089\n",
      "Sharpe Ratio (before costs):   -1.061\n",
      "Win Rate:                       50.53%\n",
      "Total Trades:                      99\n",
      "Total Transaction Costs:     $   12.03\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 19 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 20 (20/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: TDA_TD_168_SS_1080\n",
      "Transaction cost: 0.020% per trade\n",
      "\n",
      "2. Strict filtering (filter_tda_features_strict):\n",
      "--------------------------------------------------\n",
      "✓ voids_entropy: CV=1.643, Range%=6.747\n",
      "✓ connected_components_amplitude: CV=0.378, Range%=1.969\n",
      "✓ loops_amplitude: CV=0.331, Range%=1.931\n",
      "✓ voids_amplitude: CV=1.487, Range%=12.645\n",
      "✓ voids_number_of_points: CV=0.692, Range%=3.980\n",
      "\n",
      "============================================================\n",
      "Selected: 5/9 features\n",
      "\n",
      "Removed 4 flat features:\n",
      "  ❌ connected_components_entropy: CV=0.012, Range%=0.069\n",
      "  ❌ loops_entropy: CV=0.011, Range%=0.068\n",
      "  ❌ connected_components_number_of_points: CV=0.000, Range%=0.000\n",
      "  ❌ loops_number_of_points: CV=0.039, Range%=0.212\n",
      "============================================================\n",
      "Result: ['voids_entropy', 'connected_components_amplitude', 'loops_amplitude', 'voids_amplitude', 'voids_number_of_points']\n",
      "Using 5 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 6\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 132\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.12 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.25 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=-0.07 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=0.09 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=2.02 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=81888, episode_reward=2.75 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=2.55 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):   1528.87%\n",
      "Total Return (before costs):  1600.12%\n",
      "Sharpe Ratio (after costs):     2.392\n",
      "Sharpe Ratio (before costs):    2.422\n",
      "Win Rate:                       57.49%\n",
      "Total Trades:                     107\n",
      "Total Transaction Costs:     $  258.87\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 20 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 21 (21/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: FRUITS\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 4 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:Improved Environment initialized:\n",
      "\n",
      "  - Features in df: 5  - Features in df: 5\n",
      "\n",
      "  - Lookback window: 20  - Lookback window: 20\n",
      "\n",
      "  - Expected observation size: 111  - Expected observation size: 111\n",
      "\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Transaction cost: 0.0200% per trade  - Transaction cost: 0.0200% per trade\n",
      "\n",
      "  - Cost per position flip: 0.0400% (2 trades)  - Cost per position flip: 0.0400% (2 trades)\n",
      "\n",
      "  - Initial position: LONG  - Initial position: LONG\n",
      "\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 5\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 5\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 111\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 111\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 5\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 111\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=0.04 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=-2.20 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=-0.65 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-1.27 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=-0.22 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-0.05 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -95.86%\n",
      "Total Return (before costs):   -95.57%\n",
      "Sharpe Ratio (after costs):    -1.530\n",
      "Sharpe Ratio (before costs):   -1.484\n",
      "Win Rate:                       47.59%\n",
      "Total Trades:                     167\n",
      "Total Transaction Costs:     $   25.49\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 21 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 22 (22/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: NetF\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 15 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 16\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 342\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 16\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 342\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 16\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 342\n",
      "Improved Environment initialized:  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Features in df: 16\n",
      "  - Lookback window: 20\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Expected observation size: 342\n",
      "  - Cost per position flip: 0.0400% (2 trades)  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "\n",
      "  - Initial position: LONG\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 16\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 342\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-1.35 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=-1.57 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=40944, episode_reward=-0.71 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54592, episode_reward=-0.06 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=68240, episode_reward=-0.99 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=-0.87 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=95536, episode_reward=-1.86 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):    -83.66%\n",
      "Total Return (before costs):   -82.88%\n",
      "Sharpe Ratio (after costs):    -0.577\n",
      "Sharpe Ratio (before costs):   -0.544\n",
      "Win Rate:                       48.40%\n",
      "Total Trades:                     117\n",
      "Total Transaction Costs:     $   29.52\n",
      "\n",
      "⚠️  No edge before costs - features not predictive\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 22 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Processing Scenario 23 (23/23)\n",
      "================================================================================\n",
      "Asset: ADAUSDT, Feature Family: baseline\n",
      "Transaction cost: 0.020% per trade\n",
      "Using 10 features\n",
      "Train: 853 samples, Val: 395 samples\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 11\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 237\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 11\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 237\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 11\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 237\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 11\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 237\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Improved Environment initialized:\n",
      "  - Features in df: 11\n",
      "  - Lookback window: 20\n",
      "  - Expected observation size: 237\n",
      "  - Action space: 0=Long, 1=Short (ALWAYS IN MARKET)\n",
      "  - Transaction cost: 0.0200% per trade\n",
      "  - Cost per position flip: 0.0400% (2 trades)\n",
      "  - Initial position: LONG\n",
      "Training for 100,000 timesteps...\n",
      "Eval num_timesteps=13648, episode_reward=-0.23 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=27296, episode_reward=0.11 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40944, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=54592, episode_reward=0.10 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=68240, episode_reward=-0.81 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Eval num_timesteps=81888, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=95536, episode_reward=0.03 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "Training complete!\n",
      "\n",
      "------------------------------------------------------------\n",
      "RESULTS SUMMARY\n",
      "------------------------------------------------------------\n",
      "Total Return (after costs):     32.25%\n",
      "Total Return (before costs):    42.47%\n",
      "Sharpe Ratio (after costs):     0.625\n",
      "Sharpe Ratio (before costs):    0.677\n",
      "Win Rate:                       51.07%\n",
      "Total Trades:                     186\n",
      "Total Transaction Costs:     $   75.98\n",
      "\n",
      "✓ Profitable after costs!\n",
      "------------------------------------------------------------\n",
      "✓ Scenario 23 complete!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BATCH PROCESSING COMPLETE!\n",
      "================================================================================\n",
      "Processed 22 scenarios successfully\n"
     ]
    }
   ],
   "source": [
    "# Track batch results\n",
    "batch_summary = []\n",
    "\n",
    "for idx, scenario_id in enumerate(list_scenario_id):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Processing Scenario {scenario_id} ({idx+1}/{len(list_scenario_id)})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Get the scenario data\n",
    "        scenario_data = get_scenario_data(scenario_id, scenario_config)\n",
    "        print(f\"Asset: {scenario_data['asset']}, Feature Family: {scenario_data['feature_family']}\")\n",
    "\n",
    "        # Determine transaction cost\n",
    "        transaction_cost = get_transaction_cost(scenario_data['asset'])\n",
    "        print(f\"Transaction cost: {transaction_cost*100:.3f}% per trade\")\n",
    "\n",
    "        # Import the features and raw data\n",
    "        features_full_path = f\"../{scenario_data['feature_path']}/{scenario_data['feature_file']}\"\n",
    "        df_features = pd.read_csv(features_full_path)\n",
    "\n",
    "        # Format date based on feature family\n",
    "        if scenario_data['feature_family'].startswith('TDA'):\n",
    "            df_features['date'] = pd.to_datetime(df_features['end_date'])\n",
    "            df_features['date'] = df_features['date'].dt.floor('d')        \n",
    "        else:\n",
    "            df_features['date'] = pd.to_datetime(df_features['date'])\n",
    "\n",
    "        # Set date as index\n",
    "        df_features.set_index('date', inplace=True)\n",
    "\n",
    "        # Get the features for the scenario\n",
    "        list_features = get_family_members(scenario_data['feature_family'], feature_family)\n",
    "\n",
    "        # # Filter TDA features\n",
    "        # if scenario_data['feature_family'].startswith('TDA'):\n",
    "        #     list_features = [f for f in list_features if f.endswith('_entropy') or f.endswith('_amplitude')]\n",
    "\n",
    "        # Filter TDA features to remove flat ones\n",
    "        if scenario_data['feature_family'].startswith('TDA'):\n",
    "            # print(\"\\n1. Standard filtering (filter_tda_features):\")\n",
    "            # print(\"-\" * 50)\n",
    "            # selected = filter_tda_features(df_features, list_features, verbose=True)\n",
    "            # print(f\"Result: {selected}\")\n",
    "            \n",
    "            print(\"\\n2. Strict filtering (filter_tda_features_strict):\")\n",
    "            print(\"-\" * 50)\n",
    "            list_features = filter_tda_features_strict(df_features, list_features, min_cv=0.1, min_range_pct=0.2, verbose=True)\n",
    "            print(f\"Result: {list_features}\")        \n",
    "\n",
    "        df_features = df_features[list_features]\n",
    "        print(f\"Using {len(list_features)} features\")\n",
    "\n",
    "        # Load raw price data\n",
    "        raw_full_path = f\"../{scenario_data['raw_path']}/{scenario_data['raw_file']}\"\n",
    "        df_raw = pd.read_csv(raw_full_path)\n",
    "        df_raw['date'] = pd.to_datetime(df_raw['date'])\n",
    "        df_raw.set_index('date', inplace=True)\n",
    "\n",
    "        # Align features with raw data timestamps\n",
    "        df_features_modified = pd.DataFrame()\n",
    "        for date in df_features.index:\n",
    "            if date in df_raw.index:\n",
    "                df_features_modified = pd.concat([df_features_modified, df_features.loc[[date]]])\n",
    "            else:\n",
    "                date_only = date.date()\n",
    "                df_raw_date = df_raw[df_raw.index.date == date_only]\n",
    "                if not df_raw_date.empty:\n",
    "                    last_time = df_raw_date.index.max()\n",
    "                    df_features_modified = pd.concat([df_features_modified, df_features.loc[[date]].rename(index={date: last_time})])\n",
    "\n",
    "            df_features_modified = df_features_modified[~df_features_modified.index.duplicated(keep='last')]\n",
    "\n",
    "        # Join features with raw data\n",
    "        df = df_features_modified.join(df_raw, how='inner')\n",
    "        df = df[list_features + ['close']]\n",
    "\n",
    "        # Split train/validation\n",
    "        df_train = df.loc[(df.index >= scenario_data['start_train_date']) & (df.index <= scenario_data['end_train_date'])]\n",
    "        df_val = df.loc[(df.index >= scenario_data['start_val_date']) & (df.index <= scenario_data['end_val_date'])]    \n",
    "        print(f\"Train: {len(df_train)} samples, Val: {len(df_val)} samples\")\n",
    "\n",
    "        # Scale features\n",
    "        for feature in list_features:\n",
    "            df_train[feature].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            df_val[feature].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            \n",
    "            df_train[feature].fillna(method='ffill', inplace=True)\n",
    "            df_val[feature].fillna(method='ffill', inplace=True)\n",
    "            \n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            df_train[feature] = scaler.fit_transform(df_train[feature].values.reshape(-1, 1))\n",
    "            df_val[feature] = scaler.transform(df_val[feature].values.reshape(-1, 1)) \n",
    "\n",
    "        # Create environments with IMPROVED environment\n",
    "        def make_env(df, rank):\n",
    "            def _init():\n",
    "                env = ImprovedTradingEnv(df, transaction_cost=transaction_cost)\n",
    "                return env\n",
    "            return _init\n",
    "                \n",
    "        n_envs = 4\n",
    "        train_env = SubprocVecEnv([make_env(df_train, i) for i in range(n_envs)])\n",
    "        val_env = DummyVecEnv([lambda: ImprovedTradingEnv(df_val, transaction_cost=transaction_cost)])\n",
    "\n",
    "        # Create DQN model\n",
    "        model = DQN(\n",
    "            \"MlpPolicy\",\n",
    "            train_env,\n",
    "            learning_rate=1e-4,\n",
    "            learning_starts=1000,\n",
    "            buffer_size=50000,\n",
    "            batch_size=64,\n",
    "            gamma=0.99,\n",
    "            target_update_interval=500,\n",
    "            exploration_fraction=0.3,\n",
    "            exploration_initial_eps=1.0,\n",
    "            exploration_final_eps=0.05,\n",
    "            train_freq=4,\n",
    "            gradient_steps=1,\n",
    "            tensorboard_log=f\"../RL_outputs/tensorboard/{scenario_id}\",\n",
    "            verbose=0,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        # Training configuration\n",
    "        total_timesteps = max(100000, len(df_train) * 50)\n",
    "\n",
    "        # Callbacks\n",
    "        eval_callback = EvalCallback(\n",
    "            val_env,\n",
    "            best_model_save_path=f'../RL_outputs/models/{scenario_id}/',\n",
    "            log_path=f'../RL_outputs/logs/{scenario_id}/',\n",
    "            eval_freq=len(df_train) * n_envs,\n",
    "            n_eval_episodes=5,\n",
    "            deterministic=True,\n",
    "            render=False\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = CheckpointCallback(\n",
    "            save_freq=len(df_train) * n_envs * 5,\n",
    "            save_path=f'../RL_outputs/checkpoints/{scenario_id}/',\n",
    "            name_prefix='dqn_model'\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        print(f\"Training for {total_timesteps:,} timesteps...\")\n",
    "        model.learn(\n",
    "            total_timesteps=total_timesteps,\n",
    "            callback=[eval_callback, checkpoint_callback]\n",
    "        )     \n",
    "        print(\"Training complete!\")\n",
    "\n",
    "        # Evaluate\n",
    "        mean_reward, std_reward = evaluate_policy(model, val_env, n_eval_episodes=10, deterministic=False)\n",
    "\n",
    "        # Run full episode with CORRECTED cost tracking\n",
    "        obs = val_env.reset()\n",
    "        done = False\n",
    "        \n",
    "        episode_diagnostics = {\n",
    "            'dates': [],\n",
    "            'actions': [],\n",
    "            'rewards': [],\n",
    "            'positions': [],\n",
    "            'prices': [],\n",
    "            'net_worth': [],\n",
    "            'net_worth_before_costs': [],\n",
    "            'costs': [],\n",
    "            'cumulative_costs': [],\n",
    "        }\n",
    "        \n",
    "        prev_total_costs = 0\n",
    "\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, rewards, done, info = val_env.step(action)\n",
    "            \n",
    "            episode_diagnostics['dates'].append(info[0]['current_date'])\n",
    "            episode_diagnostics['actions'].append(action[0])\n",
    "            episode_diagnostics['rewards'].append(rewards[0])\n",
    "            episode_diagnostics['positions'].append(info[0]['position'])\n",
    "            episode_diagnostics['prices'].append(info[0]['close_price'])\n",
    "            episode_diagnostics['net_worth'].append(info[0]['net_worth'])\n",
    "            episode_diagnostics['net_worth_before_costs'].append(info[0]['net_worth_before_costs'])\n",
    "            \n",
    "            # FIX: Get costs directly from environment\n",
    "            current_total_costs = info[0]['total_transaction_costs']\n",
    "            cost_this_step = current_total_costs - prev_total_costs\n",
    "            prev_total_costs = current_total_costs\n",
    "            \n",
    "            episode_diagnostics['costs'].append(cost_this_step)\n",
    "            episode_diagnostics['cumulative_costs'].append(current_total_costs)\n",
    "\n",
    "        # Create results dataframe\n",
    "        df_results = pd.DataFrame(episode_diagnostics)\n",
    "        df_results['date'] = pd.to_datetime(df_results['dates'])\n",
    "\n",
    "        # Verify data quality\n",
    "        negative_costs = df_results[df_results['costs'] < -0.0001]\n",
    "        if len(negative_costs) > 0:\n",
    "            print(f\"⚠️  WARNING: {len(negative_costs)} steps with negative costs!\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"RESULTS SUMMARY\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Total Return (after costs):  {info[0]['total_return']*100:>8.2f}%\")\n",
    "        print(f\"Total Return (before costs): {info[0]['total_return_before_costs']*100:>8.2f}%\")\n",
    "        print(f\"Sharpe Ratio (after costs):  {info[0]['sharpe_ratio']:>8.3f}\")\n",
    "        print(f\"Sharpe Ratio (before costs): {info[0]['sharpe_ratio_before_costs']:>8.3f}\")\n",
    "        print(f\"Win Rate:                    {info[0]['win_rate']*100:>8.2f}%\")\n",
    "        print(f\"Total Trades:                {info[0]['trade_count']:>8.0f}\")\n",
    "        print(f\"Total Transaction Costs:     ${info[0]['total_transaction_costs']:>8.2f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if info[0]['total_return_before_costs'] < 0:\n",
    "            print(\"\\n⚠️  No edge before costs - features not predictive\")\n",
    "        elif info[0]['total_return'] < 0:\n",
    "            print(\"\\n⚠️  Profitable before costs, loses after - overtrading\")\n",
    "        else:\n",
    "            print(\"\\n✓ Profitable after costs!\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "        # Save detailed results\n",
    "        df_results.to_csv(f'../RL_outputs/results/df/{scenario_id}_DQN_results.csv', index=False)        \n",
    "\n",
    "        # Save metrics JSON\n",
    "        results = {\n",
    "            'scenario_id': scenario_id,\n",
    "            'asset': scenario_data['asset'],\n",
    "            'feature_family': scenario_data['feature_family'],\n",
    "            'transaction_cost_pct': transaction_cost * 100,\n",
    "            'mean_reward': float(df_results['rewards'].mean()),\n",
    "            'std_reward': float(df_results['rewards'].std()),\n",
    "            'final_net_worth': float(df_results['net_worth'].iloc[-1]),\n",
    "            'final_net_worth_before_costs': float(df_results['net_worth_before_costs'].iloc[-1]),\n",
    "            'total_return': float(info[0]['total_return']),\n",
    "            'total_return_before_costs': float(info[0]['total_return_before_costs']),\n",
    "            'sharpe_ratio': float(info[0]['sharpe_ratio']),\n",
    "            'sharpe_ratio_before_costs': float(info[0]['sharpe_ratio_before_costs']),\n",
    "            'sortino_ratio': float(info[0]['sortino_ratio']),\n",
    "            'max_drawdown': float(info[0]['max_drawdown']),\n",
    "            'win_rate': float(info[0]['win_rate']),\n",
    "            'win_rate_before_costs': float(info[0]['win_rate_before_costs']),\n",
    "            'policy_mean_reward': float(mean_reward),\n",
    "            'policy_std_reward': float(std_reward),\n",
    "            'total_transaction_costs': float(info[0]['total_transaction_costs']),\n",
    "            'trade_count': int(info[0]['trade_count']),\n",
    "            'trade_frequency': float(info[0]['trade_frequency']),\n",
    "        }\n",
    "\n",
    "        with open(f\"../RL_outputs/results/json/{scenario_id}_DQN_results.json\", 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "        # Track for batch summary\n",
    "        batch_summary.append(results)\n",
    "\n",
    "        # Create visualization\n",
    "        fig = make_subplots(\n",
    "            rows=6, cols=1, \n",
    "            shared_xaxes=True, \n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=(\n",
    "                \"Price and Positions\", \n",
    "                \"Rewards\", \n",
    "                \"Net Worth (Before vs After Costs)\",\n",
    "                \"Features\", \n",
    "                \"Transaction Costs\", \n",
    "                \"Cumulative Costs\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Plot 1: Price and positions\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_results['date'], y=df_results['prices'], \n",
    "                       name='Price', line=dict(color='gray', width=1)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Add position markers (0=Long, 1=Short)\n",
    "        long_mask = df_results['actions'] == 0\n",
    "        short_mask = df_results['actions'] == 1\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_results[long_mask]['date'], y=df_results[long_mask]['prices'],\n",
    "                       mode='markers', name='Long', \n",
    "                       marker=dict(color='green', size=4, symbol='triangle-up')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_results[short_mask]['date'], y=df_results[short_mask]['prices'],\n",
    "                       mode='markers', name='Short', \n",
    "                       marker=dict(color='red', size=4, symbol='triangle-down')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Plot 2: Rewards\n",
    "        colors = ['green' if r >= 0 else 'red' for r in df_results['rewards']]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=df_results['date'], y=df_results['rewards'],\n",
    "                   name='Rewards', marker_color=colors, showlegend=False),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        # Plot 3: Net worth comparison\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_results['date'], y=df_results['net_worth'],\n",
    "                       name='After Costs', line=dict(color='blue', width=2)),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_results['date'], y=df_results['net_worth_before_costs'],\n",
    "                       name='Before Costs', line=dict(color='lightblue', width=2, dash='dash')),\n",
    "            row=3, col=1\n",
    "        )\n",
    "\n",
    "        # Plot 4: Features (sample)\n",
    "        for i, feature in enumerate(list_features[:5]):  # Show only first 5\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=df_val.index, y=df_val[feature], \n",
    "                           name=feature, line=dict(width=1), showlegend=False),\n",
    "                row=4, col=1\n",
    "            )\n",
    "\n",
    "        # Plot 5: Transaction costs per step\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=df_results['date'], y=df_results['costs'],\n",
    "                   name='Costs', marker_color='orange', showlegend=False),\n",
    "            row=5, col=1\n",
    "        )\n",
    "\n",
    "        # Plot 6: Cumulative costs\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_results['date'], y=df_results['cumulative_costs'],\n",
    "                       name='Cumulative', line=dict(color='red', width=2), showlegend=False),\n",
    "            row=6, col=1\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=1400,\n",
    "            title_text=f\"Scenario {scenario_id} - {scenario_data['asset']} - {scenario_data['feature_family']}<br>\" +\n",
    "                       f\"Return: {info[0]['total_return']*100:.2f}% (Before: {info[0]['total_return_before_costs']*100:.2f}%)\",\n",
    "            showlegend=True\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(title_text=\"Date\", row=6, col=1)\n",
    "        fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Reward\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Net Worth ($)\", row=3, col=1)\n",
    "        fig.update_yaxes(title_text=\"Feature Value\", row=4, col=1)\n",
    "        fig.update_yaxes(title_text=\"Cost ($)\", row=5, col=1)\n",
    "        fig.update_yaxes(title_text=\"Cumulative ($)\", row=6, col=1)\n",
    "\n",
    "        # Save plot\n",
    "        fig.write_html(f\"../RL_outputs/results/plot/scenario_{scenario_id}_DQN_trading_analysis.html\")\n",
    "        fig.write_image(f\"../RL_outputs/results/plot/scenario_{scenario_id}_DQN_trading_analysis.png\")        \n",
    "        \n",
    "        print(f\"✓ Scenario {scenario_id} complete!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR in scenario {scenario_id}: {str(e)}\")\n",
    "        print(f\"Continuing to next scenario...\\n\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH PROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Processed {len(batch_summary)} scenarios successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Summary Statistics:\n",
      "============================================================\n",
      "Total scenarios processed: 22\n",
      "\n",
      "Profitable (after costs): 7\n",
      "Profitable (before costs): 8\n",
      "\n",
      "Mean return (after costs): 44.24%\n",
      "Mean return (before costs): 51.17%\n",
      "\n",
      "Mean Sharpe (after costs): -0.002\n",
      "Mean Sharpe (before costs): 0.030\n",
      "\n",
      "Mean trade count: 116\n",
      "Mean total costs: $56.25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_family</th>\n",
       "      <th>transaction_cost_pct</th>\n",
       "      <th>mean_reward</th>\n",
       "      <th>std_reward</th>\n",
       "      <th>final_net_worth</th>\n",
       "      <th>final_net_worth_before_costs</th>\n",
       "      <th>total_return</th>\n",
       "      <th>total_return_before_costs</th>\n",
       "      <th>...</th>\n",
       "      <th>sharpe_ratio_before_costs</th>\n",
       "      <th>sortino_ratio</th>\n",
       "      <th>max_drawdown</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>win_rate_before_costs</th>\n",
       "      <th>policy_mean_reward</th>\n",
       "      <th>policy_std_reward</th>\n",
       "      <th>total_transaction_costs</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>trade_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>SMA</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.060950</td>\n",
       "      <td>1002.639355</td>\n",
       "      <td>1016.371161</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>0.709139</td>\n",
       "      <td>-0.834801</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1.180900</td>\n",
       "      <td>0.330731</td>\n",
       "      <td>16.671770</td>\n",
       "      <td>34</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>EMA</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>1970.794960</td>\n",
       "      <td>2009.007533</td>\n",
       "      <td>0.970795</td>\n",
       "      <td>1.009008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916043</td>\n",
       "      <td>1.591367</td>\n",
       "      <td>-0.570212</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.914872</td>\n",
       "      <td>0.190236</td>\n",
       "      <td>40.678113</td>\n",
       "      <td>48</td>\n",
       "      <td>0.128342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>RSI</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.060997</td>\n",
       "      <td>929.684944</td>\n",
       "      <td>975.017365</td>\n",
       "      <td>-0.070315</td>\n",
       "      <td>-0.024983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417373</td>\n",
       "      <td>0.609382</td>\n",
       "      <td>-0.686823</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.570384</td>\n",
       "      <td>0.241808</td>\n",
       "      <td>72.990997</td>\n",
       "      <td>119</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.061009</td>\n",
       "      <td>371.427114</td>\n",
       "      <td>376.363447</td>\n",
       "      <td>-0.628573</td>\n",
       "      <td>-0.623637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>-0.796279</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.079665</td>\n",
       "      <td>0.384906</td>\n",
       "      <td>9.268659</td>\n",
       "      <td>33</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>BB</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.000742</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>411.036402</td>\n",
       "      <td>423.556866</td>\n",
       "      <td>-0.588964</td>\n",
       "      <td>-0.576443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167119</td>\n",
       "      <td>-0.321488</td>\n",
       "      <td>-0.739375</td>\n",
       "      <td>0.497326</td>\n",
       "      <td>0.497326</td>\n",
       "      <td>-0.364021</td>\n",
       "      <td>0.300112</td>\n",
       "      <td>19.649520</td>\n",
       "      <td>75</td>\n",
       "      <td>0.200535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>SO</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.061032</td>\n",
       "      <td>408.879038</td>\n",
       "      <td>433.647124</td>\n",
       "      <td>-0.591121</td>\n",
       "      <td>-0.566353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106345</td>\n",
       "      <td>0.066026</td>\n",
       "      <td>-0.857402</td>\n",
       "      <td>0.521390</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.132973</td>\n",
       "      <td>0.161343</td>\n",
       "      <td>48.801576</td>\n",
       "      <td>147</td>\n",
       "      <td>0.393048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>ATR</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.061014</td>\n",
       "      <td>454.685266</td>\n",
       "      <td>459.255848</td>\n",
       "      <td>-0.545315</td>\n",
       "      <td>-0.540744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138967</td>\n",
       "      <td>0.140774</td>\n",
       "      <td>-0.867080</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.091328</td>\n",
       "      <td>0.236492</td>\n",
       "      <td>9.488002</td>\n",
       "      <td>25</td>\n",
       "      <td>0.066845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>lagged</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>2997.751586</td>\n",
       "      <td>3272.257328</td>\n",
       "      <td>1.997752</td>\n",
       "      <td>2.272257</td>\n",
       "      <td>...</td>\n",
       "      <td>1.254839</td>\n",
       "      <td>2.275295</td>\n",
       "      <td>-0.584037</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>1.576298</td>\n",
       "      <td>0.296770</td>\n",
       "      <td>192.381158</td>\n",
       "      <td>219</td>\n",
       "      <td>0.585561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>datetime</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.060949</td>\n",
       "      <td>157.690120</td>\n",
       "      <td>163.995614</td>\n",
       "      <td>-0.842310</td>\n",
       "      <td>-0.836004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815963</td>\n",
       "      <td>-1.243326</td>\n",
       "      <td>-0.905909</td>\n",
       "      <td>0.475936</td>\n",
       "      <td>0.475936</td>\n",
       "      <td>-0.911853</td>\n",
       "      <td>0.616489</td>\n",
       "      <td>12.559392</td>\n",
       "      <td>98</td>\n",
       "      <td>0.262032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>difference_and_change</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.061002</td>\n",
       "      <td>312.188270</td>\n",
       "      <td>337.519079</td>\n",
       "      <td>-0.687812</td>\n",
       "      <td>-0.662481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073824</td>\n",
       "      <td>-0.132421</td>\n",
       "      <td>-0.914320</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>-0.313643</td>\n",
       "      <td>0.295605</td>\n",
       "      <td>65.496356</td>\n",
       "      <td>195</td>\n",
       "      <td>0.521390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario_id    asset         feature_family  transaction_cost_pct  \\\n",
       "0            1  ADAUSDT                    SMA                  0.02   \n",
       "1            2  ADAUSDT                    EMA                  0.02   \n",
       "2            3  ADAUSDT                    RSI                  0.02   \n",
       "3            4  ADAUSDT                   MACD                  0.02   \n",
       "4            5  ADAUSDT                     BB                  0.02   \n",
       "5            6  ADAUSDT                     SO                  0.02   \n",
       "6            7  ADAUSDT                    ATR                  0.02   \n",
       "7            8  ADAUSDT                 lagged                  0.02   \n",
       "8            9  ADAUSDT               datetime                  0.02   \n",
       "9           10  ADAUSDT  difference_and_change                  0.02   \n",
       "\n",
       "   mean_reward  std_reward  final_net_worth  final_net_worth_before_costs  \\\n",
       "0     0.002611    0.060950      1002.639355                   1016.371161   \n",
       "1     0.003446    0.060918      1970.794960                   2009.007533   \n",
       "2     0.001442    0.060997       929.684944                    975.017365   \n",
       "3    -0.000005    0.061009       371.427114                    376.363447   \n",
       "4    -0.000742    0.061023       411.036402                    423.556866   \n",
       "5     0.000212    0.061032       408.879038                    433.647124   \n",
       "6     0.000500    0.061014       454.685266                    459.255848   \n",
       "7     0.004508    0.060814      2997.751586                   3272.257328   \n",
       "8    -0.003259    0.060949       157.690120                    163.995614   \n",
       "9    -0.000544    0.061002       312.188270                    337.519079   \n",
       "\n",
       "   total_return  total_return_before_costs  ...  sharpe_ratio_before_costs  \\\n",
       "0      0.002639                   0.016371  ...                   0.692669   \n",
       "1      0.970795                   1.009008  ...                   0.916043   \n",
       "2     -0.070315                  -0.024983  ...                   0.417373   \n",
       "3     -0.628573                  -0.623637  ...                   0.010245   \n",
       "4     -0.588964                  -0.576443  ...                  -0.167119   \n",
       "5     -0.591121                  -0.566353  ...                   0.106345   \n",
       "6     -0.545315                  -0.540744  ...                   0.138967   \n",
       "7      1.997752                   2.272257  ...                   1.254839   \n",
       "8     -0.842310                  -0.836004  ...                  -0.815963   \n",
       "9     -0.687812                  -0.662481  ...                  -0.073824   \n",
       "\n",
       "   sortino_ratio  max_drawdown  win_rate  win_rate_before_costs  \\\n",
       "0       0.709139     -0.834801  0.529412               0.529412   \n",
       "1       1.591367     -0.570212  0.513369               0.513369   \n",
       "2       0.609382     -0.686823  0.540107               0.540107   \n",
       "3       0.001020     -0.796279  0.524064               0.524064   \n",
       "4      -0.321488     -0.739375  0.497326               0.497326   \n",
       "5       0.066026     -0.857402  0.521390               0.524064   \n",
       "6       0.140774     -0.867080  0.500000               0.500000   \n",
       "7       2.275295     -0.584037  0.502674               0.502674   \n",
       "8      -1.243326     -0.905909  0.475936               0.475936   \n",
       "9      -0.132421     -0.914320  0.524064               0.524064   \n",
       "\n",
       "   policy_mean_reward  policy_std_reward  total_transaction_costs  \\\n",
       "0            1.180900           0.330731                16.671770   \n",
       "1            0.914872           0.190236                40.678113   \n",
       "2            0.570384           0.241808                72.990997   \n",
       "3            0.079665           0.384906                 9.268659   \n",
       "4           -0.364021           0.300112                19.649520   \n",
       "5            0.132973           0.161343                48.801576   \n",
       "6            0.091328           0.236492                 9.488002   \n",
       "7            1.576298           0.296770               192.381158   \n",
       "8           -0.911853           0.616489                12.559392   \n",
       "9           -0.313643           0.295605                65.496356   \n",
       "\n",
       "   trade_count  trade_frequency  \n",
       "0           34         0.090909  \n",
       "1           48         0.128342  \n",
       "2          119         0.318182  \n",
       "3           33         0.088235  \n",
       "4           75         0.200535  \n",
       "5          147         0.393048  \n",
       "6           25         0.066845  \n",
       "7          219         0.585561  \n",
       "8           98         0.262032  \n",
       "9          195         0.521390  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create batch summary dataframe\n",
    "df_batch_summary = pd.DataFrame(batch_summary)\n",
    "\n",
    "# Save batch summary\n",
    "df_batch_summary.to_csv('../RL_outputs/results/DQL_batch_summary.csv', index=False)\n",
    "\n",
    "print(\"Batch Summary Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total scenarios processed: {len(df_batch_summary)}\")\n",
    "print(f\"\\nProfitable (after costs): {len(df_batch_summary[df_batch_summary['total_return'] > 0])}\")\n",
    "print(f\"Profitable (before costs): {len(df_batch_summary[df_batch_summary['total_return_before_costs'] > 0])}\")\n",
    "print(f\"\\nMean return (after costs): {df_batch_summary['total_return'].mean()*100:.2f}%\")\n",
    "print(f\"Mean return (before costs): {df_batch_summary['total_return_before_costs'].mean()*100:.2f}%\")\n",
    "print(f\"\\nMean Sharpe (after costs): {df_batch_summary['sharpe_ratio'].mean():.3f}\")\n",
    "print(f\"Mean Sharpe (before costs): {df_batch_summary['sharpe_ratio_before_costs'].mean():.3f}\")\n",
    "print(f\"\\nMean trade count: {df_batch_summary['trade_count'].mean():.0f}\")\n",
    "print(f\"Mean total costs: ${df_batch_summary['total_transaction_costs'].mean():.2f}\")\n",
    "\n",
    "df_batch_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Scenarios by Return (After Costs):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_family</th>\n",
       "      <th>total_return</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>trade_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>TDA_TD_168_SS_1080</td>\n",
       "      <td>15.288732</td>\n",
       "      <td>2.391688</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>lagged</td>\n",
       "      <td>1.997752</td>\n",
       "      <td>1.193718</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>EMA</td>\n",
       "      <td>0.970795</td>\n",
       "      <td>0.902640</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>TDA_TD_72_SS_336</td>\n",
       "      <td>0.886412</td>\n",
       "      <td>0.873525</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.322491</td>\n",
       "      <td>0.625021</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>TDA_TD_168_SS_504</td>\n",
       "      <td>0.269360</td>\n",
       "      <td>0.591972</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>SMA</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.683158</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>TDA_TD_72_SS_1080</td>\n",
       "      <td>-0.030893</td>\n",
       "      <td>0.664294</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>RSI</td>\n",
       "      <td>-0.070315</td>\n",
       "      <td>0.384236</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>ATR</td>\n",
       "      <td>-0.545315</td>\n",
       "      <td>0.132064</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scenario_id    asset      feature_family  total_return  sharpe_ratio  \\\n",
       "18           20  ADAUSDT  TDA_TD_168_SS_1080     15.288732      2.391688   \n",
       "7             8  ADAUSDT              lagged      1.997752      1.193718   \n",
       "1             2  ADAUSDT                 EMA      0.970795      0.902640   \n",
       "11           13  ADAUSDT    TDA_TD_72_SS_336      0.886412      0.873525   \n",
       "21           23  ADAUSDT            baseline      0.322491      0.625021   \n",
       "16           18  ADAUSDT   TDA_TD_168_SS_504      0.269360      0.591972   \n",
       "0             1  ADAUSDT                 SMA      0.002639      0.683158   \n",
       "14           16  ADAUSDT   TDA_TD_72_SS_1080     -0.030893      0.664294   \n",
       "2             3  ADAUSDT                 RSI     -0.070315      0.384236   \n",
       "6             7  ADAUSDT                 ATR     -0.545315      0.132064   \n",
       "\n",
       "    trade_count  \n",
       "18          107  \n",
       "7           219  \n",
       "1            48  \n",
       "11          163  \n",
       "21          186  \n",
       "16          110  \n",
       "0            34  \n",
       "14           79  \n",
       "2           119  \n",
       "6            25  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 performers (after costs)\n",
    "print(\"\\nTop 10 Scenarios by Return (After Costs):\")\n",
    "df_batch_summary.nlargest(10, 'total_return')[[\n",
    "    'scenario_id', 'asset', 'feature_family', \n",
    "    'total_return', 'sharpe_ratio', 'trade_count'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenarios with NO edge (negative before costs): 14\n",
      "These feature families may not work for these assets/timeframes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_family</th>\n",
       "      <th>total_return_before_costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>RSI</td>\n",
       "      <td>-0.024983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>-0.623637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>BB</td>\n",
       "      <td>-0.576443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>SO</td>\n",
       "      <td>-0.566353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>ATR</td>\n",
       "      <td>-0.540744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>datetime</td>\n",
       "      <td>-0.836004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>difference_and_change</td>\n",
       "      <td>-0.662481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>temporal_decomposition</td>\n",
       "      <td>-0.982950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>TDA_TD_72_SS_504</td>\n",
       "      <td>-0.585262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>TDA_TD_72_SS_720</td>\n",
       "      <td>-0.748470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scenario_id    asset          feature_family  total_return_before_costs\n",
       "2             3  ADAUSDT                     RSI                  -0.024983\n",
       "3             4  ADAUSDT                    MACD                  -0.623637\n",
       "4             5  ADAUSDT                      BB                  -0.576443\n",
       "5             6  ADAUSDT                      SO                  -0.566353\n",
       "6             7  ADAUSDT                     ATR                  -0.540744\n",
       "8             9  ADAUSDT                datetime                  -0.836004\n",
       "9            10  ADAUSDT   difference_and_change                  -0.662481\n",
       "10           11  ADAUSDT  temporal_decomposition                  -0.982950\n",
       "12           14  ADAUSDT        TDA_TD_72_SS_504                  -0.585262\n",
       "13           15  ADAUSDT        TDA_TD_72_SS_720                  -0.748470"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scenarios with no edge (negative before costs)\n",
    "no_edge = df_batch_summary[df_batch_summary['total_return_before_costs'] < 0]\n",
    "print(f\"\\nScenarios with NO edge (negative before costs): {len(no_edge)}\")\n",
    "print(\"These feature families may not work for these assets/timeframes\")\n",
    "no_edge[['scenario_id', 'asset', 'feature_family', 'total_return_before_costs']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
